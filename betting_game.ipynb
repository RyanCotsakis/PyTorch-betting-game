{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e075e24d-0119-433a-bf70-a53e986d4251",
   "metadata": {},
   "source": [
    "# Betting Game\n",
    "\n",
    "## Rules of the game:\n",
    "1. Everyone puts 1 euro in the pot. \n",
    "2. Each player has a uniform random variable, and the active player has the choice to bet (at least 1 euro) on having the highest number, or fold. Whether he bets or not, play continues to the left.\n",
    "3. If there was a bet from any previous player, the active player has the choice of either calling or folding. Play continues to the left.\n",
    "4. Play stops once everyone has acted once. The hands are revealed, and of the remaining players (who have not folded), he with the highest number wins the pot. Side pots are calculated appropriately.\n",
    "\n",
    "## Capabilities of the agents\n",
    "- **Randomized betting:** The agents are able to mask their hand and bluff. Bluffing frequencies are learned.\n",
    "- **Bets and calls reflect player position:** Bets made in early position are considered differently than those made in late position.\n",
    "- **Continuous action space:** The agents are able to maximize expected winnings without discretizing their possible actions.\n",
    "- **Agents exhibit reasonable behaviour:** Upon observation, the algorithm works!\n",
    "\n",
    "## Limitations\n",
    "- Player histories are not remembered. Players do not learn how to exploit particularly bad play from other agents.\n",
    "- Although infrequent, some unreasonable calls are observed... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c1fc8920-3df4-4346-86de-0299e3fcf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import models, transforms # no datasets needed\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8fe37b92-d314-47f9-b4f2-605a3c63277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTI = 1 # everyone antis in at the beginning of the hand.\n",
    "\n",
    "class Player():\n",
    "    num_players = 0\n",
    "    \n",
    "    def __init__(self, stack, follow_model, lead_model, verbose=False):\n",
    "        self.stack = stack\n",
    "        self.follow_model = follow_model\n",
    "        self.lead_model = lead_model\n",
    "        self.verbose=verbose\n",
    "        Player.num_players += 1\n",
    "        self.id = Player.num_players\n",
    "        self._new_hand()\n",
    "    \n",
    "    def _new_hand(self):\n",
    "        self.hand = torch.rand(1)\n",
    "        self.folded = False\n",
    "    \n",
    "    def anti(self):\n",
    "        self._new_hand()\n",
    "        anti = np.min((ANTI, self.stack))\n",
    "        self.stack -= anti\n",
    "        return anti\n",
    "    \n",
    "    def lead(self, state, play_randomly=False):\n",
    "        state = torch.Tensor(state).unsqueeze(0)\n",
    "        raw_bet = self.lead_model(state)\n",
    "        bet = F.softplus(raw_bet) - F.softplus(raw_bet - torch.Tensor([self.stack]))\n",
    "        bet = bet.item()\n",
    "        if play_randomly:\n",
    "            bet = np.random.rand()*self.stack\n",
    "        if bet > ANTI:\n",
    "            bet = np.min((self.stack, bet))\n",
    "            if self.verbose:\n",
    "                print(\"Player {} bet {}\".format(self.id, bet))\n",
    "            self.stack -= bet\n",
    "            return bet\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def follow(self, state, play_randomly=False):\n",
    "        bet = state[-1]\n",
    "        state = torch.Tensor(state).unsqueeze(0)\n",
    "        expected_if_follow = self.follow_model(state).detach().item()\n",
    "        if play_randomly:\n",
    "            expected_if_follow = np.random.rand()-0.5\n",
    "        if expected_if_follow > 0:\n",
    "            response = np.min((self.stack, bet))\n",
    "            if self.verbose:\n",
    "                print(\"Player {} accepts\".format(self.id))\n",
    "            self.stack -= response\n",
    "            return response\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def is_active(self):\n",
    "        return self.stack > 0 and not self.folded\n",
    "    \n",
    "    def fold(self):\n",
    "        if self.verbose and self.is_active():\n",
    "            print(\"Player {} folds\".format(self.id))\n",
    "        self.folded = True\n",
    "\n",
    "\n",
    "class Recorder():\n",
    "    def __init__(self):\n",
    "        self.x_state = []\n",
    "        self.x_bet = []\n",
    "        self.y = []\n",
    "        self.initial_stacks = []\n",
    "        self.players = []\n",
    "    \n",
    "    def record_initial(self, state, player, bet):\n",
    "        self.x_state.append(state)\n",
    "        self.x_bet.append([bet])\n",
    "        self.initial_stacks.append(player.stack + bet)\n",
    "        self.players.append(player)\n",
    "\n",
    "    def record_final(self):\n",
    "        for i, p in enumerate(self.players):\n",
    "            self.y.append([p.stack - self.initial_stacks[i]])\n",
    "        self.initial_stacks = []\n",
    "        self.players = []\n",
    "        \n",
    "    def get_data(self, replicate=True):\n",
    "        if replicate:\n",
    "            x_state = torch.cat((torch.Tensor(self.x_state),\n",
    "                            torch.Tensor(self.x_state)),\n",
    "                            dim=0)\n",
    "            x_bet = torch.cat((torch.rand(len(self.x_bet),1)*ANTI,\n",
    "                            torch.Tensor(self.x_bet)),\n",
    "                            dim=0)\n",
    "            y = torch.cat((torch.zeros((len(self.y),1)),\n",
    "                          torch.Tensor(self.y)),\n",
    "                          dim=0)\n",
    "        else:\n",
    "            x_state = torch.Tensor(self.x_state)\n",
    "            x_bet = torch.Tensor(self.x_bet)\n",
    "            y = torch.Tensor(self.y)\n",
    "        inds = torch.randperm(y.shape[0])\n",
    "        return x_state[inds,:], x_bet[inds,:], y[inds,:]\n",
    "\n",
    "\n",
    "def start_hand(players, lead_index, lead_recorder=None, follow_recorder=None, p_random=0):\n",
    "    ## SETUP ##\n",
    "    contributions = {}\n",
    "    for player in players:\n",
    "        contributions[player] = player.anti()\n",
    "    n_active_players = np.sum([int(p.is_active()) for p in players])\n",
    "    remaining_players = n_active_players\n",
    "    \n",
    "    ## PLAY ##\n",
    "    someone_led = False\n",
    "    n_accepted = 0\n",
    "    for _i in range(lead_index, lead_index + len(players)):\n",
    "        player = players[_i % len(players)]\n",
    "        play_randomly = np.random.rand() < p_random\n",
    "        try:\n",
    "            remaining_players -= 1\n",
    "        except:\n",
    "            print(remaining_players)\n",
    "            raise UserWarning()\n",
    "        \n",
    "        if not player.is_active():\n",
    "            continue\n",
    "            \n",
    "        if not someone_led:\n",
    "            # see if player should lead\n",
    "            if remaining_players == 0:\n",
    "                break\n",
    "            state = [sum(contributions.values()),\n",
    "                     remaining_players,\n",
    "                     player.stack, # TODO: important that this is index 2...\n",
    "                     player.hand-0.5,\n",
    "                     torch.rand(1)-0.5 # this makes the decision randomized!\n",
    "                    ]\n",
    "            bet = player.lead(state, play_randomly)\n",
    "            contributions[player] += bet\n",
    "            if bet > ANTI:\n",
    "                someone_led = True\n",
    "                n_active_after_leader = remaining_players\n",
    "                if lead_recorder is not None:\n",
    "                    lead_recorder.record_initial(state, player, bet)\n",
    "            else:\n",
    "                player.fold()\n",
    "        else:\n",
    "            # see if player should follow\n",
    "            state = [sum(contributions.values()),\n",
    "                     n_active_after_leader,\n",
    "                     n_accepted,\n",
    "                     remaining_players,\n",
    "                     player.stack,\n",
    "                     player.hand-0.5,\n",
    "                     bet]\n",
    "            response = player.follow(state, play_randomly)\n",
    "            contributions[player] += response\n",
    "            if response > 0:\n",
    "                n_accepted += 1\n",
    "                if follow_recorder is not None:\n",
    "                    follow_recorder.record_initial(state, player, response)\n",
    "            else:\n",
    "                player.fold()\n",
    "    \n",
    "    ## SEE WHO WINS ##\n",
    "    bet_sizes = np.sort(list(set(contributions.values())))\n",
    "    j = len(bet_sizes) - 1\n",
    "    while(True):\n",
    "        big_players = [p for p, c in contributions.items() if c >= bet_sizes[j]]\n",
    "        if j > 0:\n",
    "            side_pot = len(big_players) * (bet_sizes[j] - bet_sizes[j-1])\n",
    "        else:\n",
    "            side_pot = len(big_players) * bet_sizes[0]\n",
    "        winner_index = np.argmax([-1 if p.folded else p.hand for p in big_players])\n",
    "        for i, p in enumerate(big_players):\n",
    "            if i == winner_index:\n",
    "                p.stack += side_pot\n",
    "            else:\n",
    "                p.fold()\n",
    "        if j == 0:\n",
    "            break\n",
    "        j -= 1\n",
    "        \n",
    "    for player in players:\n",
    "        if player.verbose:\n",
    "            print(\"Player {} had a {}\".format(player.id, player.hand.item()))\n",
    "        \n",
    "    if lead_recorder is not None:\n",
    "        lead_recorder.record_final()\n",
    "    if follow_recorder is not None:\n",
    "        follow_recorder.record_final()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7dfb88-c5d8-4f21-a29d-79b186229148",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "Each of the three models are of the same form. Their outputs either reflect an expected winning or a number that is transformed into an agents bet.\n",
    "\n",
    "`winnings_model`: \n",
    "- (input) state + bet.\n",
    "- (output) expected winnings.\n",
    "Attempts to evaluate the expected winnings of the leading better given a game-state and a bet. Trained on the L2 loss of its predictions and actual winning outcomes experienced in-game.\n",
    "\n",
    "`lead_model`:\n",
    "- (input) state.\n",
    "- (output) bet.\n",
    "Attempts to produce a leading bet that maximizes the output of `winnings_model` when paired with the provided game-state.\n",
    "\n",
    "`follow_model`:\n",
    "- (input) state.\n",
    "- (output) expected winnings if call.\n",
    "Attempts to evaluate the expected winnings of a caller given a game-state. Trained on the L2 loss of its predictions and actual winning outcomes experienced in-game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "abcd913f-96fe-4591-b502-153fc225f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetNN(nn.Module):\n",
    "    def __init__(self, n_state):\n",
    "        super().__init__()\n",
    "        n_hidden = 20\n",
    "        self.fc1 = nn.Linear(n_state, n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out1 = nn.Linear(n_hidden, 1)\n",
    "        self.out2 = nn.Linear(n_hidden, 1)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        state = torch.Tensor(state)\n",
    "        h = F.relu(self.fc1(state))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        x = self.out1(h)\n",
    "        pm = F.tanh(self.out2(h))\n",
    "        return x*pm\n",
    "\n",
    "lead_model = BetNN(5)\n",
    "follow_model = BetNN(7)\n",
    "winnings_model = BetNN(6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b6ae8223-61d0-46b9-b17f-1e6501ad349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_players = 6\n",
    "def get_more_data(n_hands, l_model, f_model):\n",
    "    lead_recorder = Recorder()\n",
    "    follow_recorder = Recorder()\n",
    "    for j in range(n_hands):\n",
    "        if j % 4 == 0:\n",
    "            players = [Player(50, follow_model, lead_model) for _ in range(n_players)]\n",
    "        if j %500 == 0:\n",
    "            print('{}/{} hands played'.format(j,n_hands))\n",
    "        start_hand(players, j-1, lead_recorder, follow_recorder, p_random=0.3)\n",
    "    return(lead_recorder, follow_recorder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8ca62dd8-68cc-4762-a5f0-0095db423e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_winnings(lead_recorder, model, n_epochs=30, batch_size=30, lr = 0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        x_state, x_bet, y = lead_recorder.get_data()\n",
    "        \n",
    "        x_state = torch.cat((x_state,x_bet),dim=1)\n",
    "        N = x_state.shape[0]\n",
    "        i = 0\n",
    "        total_loss = 0\n",
    "        while i + batch_size - 1 < N:\n",
    "            inds = range(i, i + batch_size)\n",
    "            \n",
    "            winnings = model.forward(x_state[inds,:])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(winnings, y[inds,:])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.detach().item()\n",
    "            \n",
    "            i += batch_size\n",
    "        print(\"Loss:\", total_loss/i)\n",
    "\n",
    "\n",
    "def train_lead(lead_recorder, l_model, w_model, n_epochs=30, batch_size=30, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(l_model.parameters(), lr = lr)\n",
    "    l_model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        x_state, _, y = lead_recorder.get_data(replicate=False)\n",
    "        \n",
    "        N = x_state.shape[0]\n",
    "        i = 0\n",
    "        total_loss = 0\n",
    "        while i + batch_size - 1 < N:\n",
    "            inds = range(i, i + batch_size)\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            raw_bet = l_model.forward(x_state[inds,:])\n",
    "            stack = x_state[inds,2].unsqueeze(1)\n",
    "            bet = F.softplus(raw_bet) - F.softplus(raw_bet - stack)\n",
    "            new_state = torch.cat((x_state[inds,:], bet), dim=1)            \n",
    "            \n",
    "            loss = -torch.mean(w_model.forward(new_state)) + 0.0005*F.mse_loss(raw_bet, torch.zeros_like(raw_bet) + ANTI)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.detach().item()\n",
    "            \n",
    "            i += batch_size\n",
    "        print(\"Loss:\", total_loss/i)\n",
    "\n",
    "        \n",
    "def train_follow(follow_recorder, f_model, n_epochs=30, batch_size=30, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(f_model.parameters(), lr = lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    f_model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        x_state, _, y = follow_recorder.get_data(replicate=False)\n",
    "        \n",
    "        N = x_state.shape[0]\n",
    "        i = 0\n",
    "        total_loss = 0\n",
    "        while i + batch_size - 1 < N:\n",
    "            inds = range(i, i + batch_size)\n",
    "    \n",
    "            winnings = f_model.forward(x_state[inds,:])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(winnings, y[inds,:])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.detach().item()\n",
    "            \n",
    "            i += batch_size\n",
    "        print(\"Loss:\", total_loss/i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca06fd7-80e7-4448-98a2-96f6f822a0cd",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4fca0-bf23-4b20-8cca-2d9ec4b2ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "bs = 100\n",
    "ne = 30\n",
    "lr = 0.001\n",
    "for _ in range(N):\n",
    "    print(\"Getting more data\")\n",
    "    lead_recorder, follow_recorder = get_more_data(10000, lead_model, follow_model)\n",
    "    for j in range(2):\n",
    "        print(\"Training winnings_model\")\n",
    "        train_winnings(lead_recorder, winnings_model, n_epochs=2*ne, batch_size=bs, lr=lr)\n",
    "        print(\"Training lead_model\")\n",
    "        train_lead(lead_recorder, lead_model, winnings_model, n_epochs=ne, batch_size=bs, lr=lr)\n",
    "        print(\"Training follow_model\")\n",
    "        train_follow(follow_recorder, follow_model, n_epochs=ne, batch_size=bs, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1c22a0-8b5f-4dbc-9027-ce346b4dcb7d",
   "metadata": {},
   "source": [
    "*[Training output suppressed]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c0f64b50-2781-488b-8548-ee3c3df9d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'winnings': winnings_model.state_dict(),\n",
    "            'lead': lead_model.state_dict(),\n",
    "            'follow': follow_model.state_dict()\n",
    "           },\n",
    "           'betting_game_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b76997-38f8-4e15-8929-b62acf674e43",
   "metadata": {},
   "source": [
    "## Test the model (watch them play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0b282c1a-0538-414b-9657-7b8a57fea3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dicts = torch.load('betting_game_checkpoint.pth')\n",
    "winnings_model.load_state_dict(state_dicts['winnings'])\n",
    "lead_model.load_state_dict(state_dicts['lead'])\n",
    "follow_model.load_state_dict(state_dicts['follow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "80ce553f-01cc-4bb8-8b2c-f83800ebe3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_players = 6\n",
    "follow_model.eval()\n",
    "lead_model.eval()\n",
    "players = [Player(50, follow_model, lead_model, verbose=True) for _ in range(n_players)]\n",
    "start_at = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "cbfa090e-adfe-4240-b618-4345b058f73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55.0, 49, 49, 49, 49, 49]\n",
      "Player 46844 folds\n",
      "Player 46845 folds\n",
      "Player 46846 folds\n",
      "Player 46847 bet 9.136346817016602\n",
      "Player 46848 folds\n",
      "Player 46843 accepts\n",
      "Player 46847 folds\n",
      "Player 46843 had a 0.7687220573425293\n",
      "Player 46844 had a 0.6723493337631226\n",
      "Player 46845 had a 0.3045359253883362\n",
      "Player 46846 had a 0.22577524185180664\n",
      "Player 46847 had a 0.7209641337394714\n",
      "Player 46848 had a 0.22134077548980713\n",
      "[69.1363468170166, 48, 48, 48, 38.8636531829834, 48]\n"
     ]
    }
   ],
   "source": [
    "print([p.stack for p in players])\n",
    "start_hand(players, start_at)\n",
    "print([p.stack.item() for p in players])\n",
    "start_at += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f3d0e-8854-44dc-9fb3-57d41d09cdb5",
   "metadata": {},
   "source": [
    "*Note: The final fold from Player 46847 is not actually a decision... It is a consequence of the procedure that decides which player wins.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
